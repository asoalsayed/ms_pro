{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from sentence_transformers import SentenceTransformer, LoggingHandler, util, models, evaluation, losses, InputExample\n",
    "from sentence_transformers.cross_encoder import CrossEncoder\n",
    "from sentence_transformers.cross_encoder.evaluation import CEBinaryClassificationEvaluator\n",
    "from datetime import datetime\n",
    "from collections import defaultdict\n",
    "from torch.utils.data import IterableDataset\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import json\n",
    "import time\n",
    "import torch\n",
    "import os\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_batch_size = 256\n",
    "model_name = 'cross-encoder/ms-marco-TinyBERT-L-6'\n",
    "model_save_path = 'models/crenc-exp1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_triplets(Passage_dict):\n",
    "    triplets = []\n",
    "    for k, v in Passage_dict.items():\n",
    "        for x in v[0]:\n",
    "            for y in v[1]:\n",
    "                triplets.append([k, x, y])\n",
    "\n",
    "    return triplets\n",
    "\n",
    "def get_dataset(triplets, corpus):\n",
    "    dataset = []        \n",
    "    for triplet in triplets:\n",
    "        qid, pos_id, neg_id = triplet\n",
    "        \n",
    "        qid = str(qid)\n",
    "        pos_id = str(pos_id)\n",
    "        neg_id = str(neg_id)\n",
    "\n",
    "        query_text = corpus[qid]\n",
    "        pos_text = corpus[pos_id]\n",
    "        neg_text = corpus[neg_id]\n",
    "\n",
    "        pos_instance = InputExample(texts=[query_text, pos_text],label=1)\n",
    "        neg_instance = InputExample(texts=[query_text, neg_text],label=0)\n",
    "\n",
    "        dataset.append(pos_instance)\n",
    "        dataset.append(neg_instance)\n",
    "\n",
    "    return dataset\n",
    "\n",
    "\n",
    "with open('./data/generated/train_passage.json', 'r') as f:\n",
    "    train_passage = json.load(f)\n",
    "\n",
    "with open('./data/generated/train_corpus.json', 'r') as f:\n",
    "    train_corpus = json.load(f)\n",
    "\n",
    "with open('./data/generated/val_passage.json', 'r') as f:\n",
    "    val_passage = json.load(f)\n",
    "\n",
    "with open('./data/generated/val_corpus.json', 'r') as f:\n",
    "    val_corpus = json.load(f)\n",
    "\n",
    "train_triplets = get_triplets(train_passage)\n",
    "train_dataset = get_dataset(train_triplets, train_corpus)\n",
    "\n",
    "val_triplets = get_triplets(val_passage)\n",
    "val_dataset = get_dataset(val_triplets, val_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Use pytorch device: cuda\n"
     ]
    }
   ],
   "source": [
    "logging.basicConfig(\n",
    "    format='- %(message)s',\n",
    "    datefmt='%Y-%m-%d %H:%M:%S',\n",
    "    level=logging.INFO,\n",
    "    handlers=[LoggingHandler()]\n",
    ")\n",
    "\n",
    "model = CrossEncoder(model_name)\n",
    "train_dataloader = DataLoader(train_dataset, shuffle=True, batch_size=train_batch_size)\n",
    "evaluator = CEBinaryClassificationEvaluator.from_input_examples(val_dataset, name='cross_encoder_val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce356e3a9cfa4d3eac263af90d3aa313",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c730fdb7786d4dbc8315873f423034e4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/3122 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- CEBinaryClassificationEvaluator: Evaluating the model on cross_encoder_val dataset in epoch 0 after 1561 steps:\n",
      "- Accuracy:           74.08\t(Threshold: 0.5425)\n",
      "- F1:                 76.21\t(Threshold: 0.2190)\n",
      "- Precision:          67.27\n",
      "- Recall:             87.90\n",
      "- Average Precision:  83.74\n",
      "\n",
      "- Save model to models/crenc-exp1\n",
      "- CEBinaryClassificationEvaluator: Evaluating the model on cross_encoder_val dataset in epoch 0 after 3122 steps:\n",
      "- Accuracy:           73.26\t(Threshold: 0.0613)\n",
      "- F1:                 76.00\t(Threshold: 0.0065)\n",
      "- Precision:          67.16\n",
      "- Recall:             87.52\n",
      "- Average Precision:  82.89\n",
      "\n",
      "- CEBinaryClassificationEvaluator: Evaluating the model on cross_encoder_val dataset after epoch 0:\n",
      "- Accuracy:           73.26\t(Threshold: 0.0613)\n",
      "- F1:                 76.00\t(Threshold: 0.0065)\n",
      "- Precision:          67.16\n",
      "- Recall:             87.52\n",
      "- Average Precision:  82.89\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "588367545f4442678334b46082b01e6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/3122 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- CEBinaryClassificationEvaluator: Evaluating the model on cross_encoder_val dataset in epoch 1 after 1561 steps:\n",
      "- Accuracy:           73.53\t(Threshold: 0.0043)\n",
      "- F1:                 75.99\t(Threshold: 0.0012)\n",
      "- Precision:          68.92\n",
      "- Recall:             84.67\n",
      "- Average Precision:  82.23\n",
      "\n",
      "- CEBinaryClassificationEvaluator: Evaluating the model on cross_encoder_val dataset in epoch 1 after 3122 steps:\n",
      "- Accuracy:           73.53\t(Threshold: 0.0021)\n",
      "- F1:                 76.10\t(Threshold: 0.0003)\n",
      "- Precision:          67.53\n",
      "- Recall:             87.17\n",
      "- Average Precision:  82.01\n",
      "\n",
      "- CEBinaryClassificationEvaluator: Evaluating the model on cross_encoder_val dataset after epoch 1:\n",
      "- Accuracy:           73.53\t(Threshold: 0.0021)\n",
      "- F1:                 76.10\t(Threshold: 0.0003)\n",
      "- Precision:          67.53\n",
      "- Recall:             87.17\n",
      "- Average Precision:  82.01\n",
      "\n"
     ]
    }
   ],
   "source": [
    "warmup_steps = int(len(train_dataloader) * 5 * 0.1)\n",
    "\n",
    "model.fit(\n",
    "    train_dataloader=train_dataloader,\n",
    "    evaluator=evaluator,\n",
    "    epochs=2,\n",
    "    evaluation_steps=int(len(train_dataloader) / 2),\n",
    "    warmup_steps=warmup_steps,\n",
    "    save_best_model=True,\n",
    "    output_path=model_save_path\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "del model\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CrossEncoder('./models/crenc-exp1/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "positives = []\n",
    "negatives = []\n",
    "\n",
    "for triplet in val_triplets:\n",
    "    query = val_corpus[triplet[0]]\n",
    "    pos = val_corpus[str(triplet[1])]\n",
    "    neg = val_corpus[str(triplet[2])]\n",
    "\n",
    "    positives.append([query, pos])\n",
    "    negatives.append([query, neg])\n",
    "\n",
    "positive_scores = model.predict(positives)\n",
    "negative_scores = model.predict(negatives)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: deployment of the pod in the aws kops cluster\n",
      "Text: arkade: set up service as a LoadBalancer\n",
      "Score:0.0356\n",
      "\n",
      "Query: DockerFile and environment variable\n",
      "Text: symfony can't install assets the first time\n",
      "Score:0.2428\n",
      "\n",
      "Query: Problem in installing nvidia-docker in windows 10 system\n",
      "Text: Keras Model stops training without indication as to why and how to enable GPU-acceleration\n",
      "Score:0.0137\n",
      "\n",
      "Query: How do you print to console from a docker file during build?\n",
      "Text: Dockerfile for NGINX Web server\n",
      "Score:0.3939\n",
      "\n",
      "Query: Docker container to bring up DB fails with connection refused error\n",
      "Text: Saving database state from library/postgres\n",
      "Score:0.3410\n",
      "\n",
      "Query: Kubernetes to find Pod IP from another Pod\n",
      "Text: Unable to install Spinnaker via Helm\n",
      "Score:0.0768\n",
      "\n",
      "Query: Mount volumes with Secrets using Python Kubernetes API\n",
      "Text: Airflow pull docker image from private google container repository\n",
      "Score:0.0093\n",
      "\n",
      "Query: Unable to send messages to port-forwarded Kafka pod\n",
      "Text: How can I use ingress-nginx via Helm on custom k8s install without LoadBalancer support?\n",
      "Score:0.0059\n",
      "\n",
      "Query: I want to get the artifact version deployed by Jenkins\n",
      "Text: how to properly build spring boot docker image using Dockerfile?\n",
      "Score:0.1517\n",
      "\n",
      "Query: aws Lambda created ENI not deleting while deletion of stack\n",
      "Text: How to import manual changes into Terraform remote state\n",
      "Score:0.0394\n",
      "\n"
     ]
    }
   ],
   "source": [
    "positive_out = np.where(positive_scores < 0.5)[0]\n",
    "negative_out = np.where(negative_scores >= 0.5)[0]\n",
    "\n",
    "# sample some bad positive samples\n",
    "for idx in np.random.choice(positive_out, 10, replace=False):\n",
    "    score = positive_scores[idx]\n",
    "    query = val_corpus[val_triplets[idx][0]]\n",
    "    text = val_corpus[str(val_triplets[idx][1])]\n",
    "\n",
    "    print(f'Query: {query}\\nText: {text}\\nScore:{score:.4f}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: Distributed JMeter in Kubernetes increase heap size\n",
      "Text: Kubernetes Scheduler Extenders - when are they invoked?\n",
      "Score:0.7508\n",
      "\n",
      "Query: Can I map gpu drivers of host machine (windows) inside docker container?\n",
      "Text: Docker mysql environment\n",
      "Score:0.8025\n",
      "\n",
      "Query: Unable to connect docker nginx with docker ubuntu\n",
      "Text: Getting 'didn't match node selector' when running Docker Windows container in Azure AKS\n",
      "Score:0.5311\n",
      "\n",
      "Query: Docker - Failing to get PGP Keys\n",
      "Text: What is the use for CRD status?\n",
      "Score:0.5260\n",
      "\n",
      "Query: Running tests for .NET Core in Docker during local dev\n",
      "Text: What is the practical purpose of VOLUME in Dockerfile?\n",
      "Score:0.7636\n",
      "\n",
      "Query: Dask - Kubernetes - Tutorial example\n",
      "Text: How to deploy frontends on kubernetes and how this can work with AWS Cloudfront?\n",
      "Score:0.6133\n",
      "\n",
      "Query: Production ready Kubernetes redis\n",
      "Text: Kubernetes Prometheus metric for HPA (horizontal pod autoscaler) `currentCPUUtilizationPercentage`?\n",
      "Score:0.8053\n",
      "\n",
      "Query: Kubernetes monitoring and self-healing\n",
      "Text: Differences between template and chart in Helm\n",
      "Score:0.8301\n",
      "\n",
      "Query: Distributed JMeter in Kubernetes increase heap size\n",
      "Text: How to properly access multiple kubernetes cluster using kubectl\n",
      "Score:0.5379\n",
      "\n",
      "Query: OAuth - \"No module named authlib\"\n",
      "Text: example on how to docker push to docker-registry running in kubernetes\n",
      "Score:0.5473\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# sample some bad negative samples\n",
    "for idx in np.random.choice(negative_out, 10, replace=False):\n",
    "    score = negative_scores[idx]\n",
    "    query = val_corpus[val_triplets[idx][0]]\n",
    "    text = val_corpus[str(val_triplets[idx][2])]\n",
    "\n",
    "    print(f'Query: {query}\\nText: {text}\\nScore:{score:.4f}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: Kubernetes Internal Ingress\n",
      "Text: How can I use ingress-nginx via Helm on custom k8s install without LoadBalancer support?\n",
      "Score:0.9078\n",
      "\n",
      "Query: Best practices for values in global section of helm values.yaml\n",
      "Text: How to pass extra configuration to RabbitMQ with Helm?\n",
      "Score:0.9927\n",
      "\n",
      "Query: Run Postgres migration with Docker/Docker compose\n",
      "Text: Why doesn't postgres official docker repo start db service at build time?\n",
      "Score:0.9922\n",
      "\n",
      "Query: AWS MWAA (Managed Apache Airflow); Programmatically enable DAGs\n",
      "Text: Create user with LDAP authentification in airflow 2.1.4\n",
      "Score:0.9923\n",
      "\n",
      "Query: Can't change kafka broker-id in Incubator Helm chart?\n",
      "Text: Setup Ingress whith Helm using the chart stable/nginx-ingress\n",
      "Score:0.9109\n",
      "\n",
      "Query: Whats exactly the difference between a programming language only image and a OS plus programming language docker image?\n",
      "Text: Best way to build a Docker image\n",
      "Score:0.9492\n",
      "\n",
      "Query: How does Kubernetes know on which node to schedule its POD when PVs are backed by logical volumes?\n",
      "Text: Kubernetes Prometheus metric for HPA (horizontal pod autoscaler) `currentCPUUtilizationPercentage`?\n",
      "Score:0.8399\n",
      "\n",
      "Query: kubernetes-dashboard cannot display metrics of metrics-server\n",
      "Text: kubernetes-dashboard cannot display metrics of metrics-server\n",
      "Score:0.9975\n",
      "\n",
      "Query: Init container not restarting on pod restart\n",
      "Text: In Kubernetes, how many namespaces can you have?\n",
      "Score:0.8584\n",
      "\n",
      "Query: How to check if CloudFormation template is correct?\n",
      "Text: What causes my SAM template to generate that many errors\n",
      "Score:0.8312\n",
      "\n"
     ]
    }
   ],
   "source": [
    "positive_good = np.where(positive_scores > 0.8)[0]\n",
    "negative_good = np.where(negative_scores < 0.2)[0]\n",
    "\n",
    "# sample some good positive samples\n",
    "for idx in np.random.choice(positive_good, 10, replace=False):\n",
    "    score = positive_scores[idx]\n",
    "    query = val_corpus[val_triplets[idx][0]]\n",
    "    text = val_corpus[str(val_triplets[idx][1])]\n",
    "\n",
    "    print(f'Query: {query}\\nText: {text}\\nScore:{score:.4f}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: Amazon Web Services: NoCredentialsError: Unable to locate credentials\n",
      "Text: Serverless NodeJS / Native node_modules\n",
      "Score:0.0041\n",
      "\n",
      "Query: Configure prometheus to collect custom metrics from dockerized nodejs pod\n",
      "Text: Kubernetes Internal Ingress\n",
      "Score:0.0087\n",
      "\n",
      "Query: the tensorflow docker gpu image doesn't detect my GPU\n",
      "Text: Keras Model stops training without indication as to why and how to enable GPU-acceleration\n",
      "Score:0.0190\n",
      "\n",
      "Query: Delete helm chart from *registry* (not uninstall from cluster; not repository)\n",
      "Text: Push existing image to another registry (without mounting docker.sock or using docker:dind)\n",
      "Score:0.0035\n",
      "\n",
      "Query: Why won't docker generate a password when creating a new mysql container?\n",
      "Text: Warning: mysqli_real_connect(): (HY000/1698): Access denied for user 'root'@'localhost' - Docker\n",
      "Score:0.0071\n",
      "\n",
      "Query: Docker mysql official image\n",
      "Text: Docker mysql environment\n",
      "Score:0.0057\n",
      "\n",
      "Query: Can't access Prometheus Postgres exporter installed in kubernetes: connection refused\n",
      "Text: How to isolate data of one persistent volume claim from another\n",
      "Score:0.1147\n",
      "\n",
      "Query: How to install nc in mysql container\n",
      "Text: Docker - Is There Any Difference Between The Two MySQL Docker Images?\n",
      "Score:0.0204\n",
      "\n",
      "Query: Python on docker to print out to stdout\n",
      "Text: Nginx in Docker container gets `connection reset` error, but works fine without a container\n",
      "Score:0.0221\n",
      "\n",
      "Query: SOLVED AWS CloudFormation Create stack. Unresolved resource dependencies\n",
      "Text: How do I make Cloudformation give more verbose debugging output?\n",
      "Score:0.0008\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# sample some good negative samples\n",
    "for idx in np.random.choice(negative_good, 10, replace=False):\n",
    "    score = negative_scores[idx]\n",
    "    query = val_corpus[val_triplets[idx][0]]\n",
    "    text = val_corpus[str(val_triplets[idx][1])]\n",
    "\n",
    "    print(f'Query: {query}\\nText: {text}\\nScore:{score:.4f}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "transformer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
